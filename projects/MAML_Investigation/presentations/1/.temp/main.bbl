% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.1 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{nyt/global//global/global}
  \entry{Denevi2018a}{article}{}
    \name{author}{4}{}{%
      {{hash=DG}{%
         family={Denevi},
         familyi={D\bibinitperiod},
         given={Giulia},
         giveni={G\bibinitperiod},
      }}%
      {{hash=CC}{%
         family={Ciliberto},
         familyi={C\bibinitperiod},
         given={Carlo},
         giveni={C\bibinitperiod},
      }}%
      {{hash=SD}{%
         family={Stamos},
         familyi={S\bibinitperiod},
         given={Dimitris},
         giveni={D\bibinitperiod},
      }}%
      {{hash=PM}{%
         family={Pontil},
         familyi={P\bibinitperiod},
         given={Massimiliano},
         giveni={M\bibinitperiod},
      }}%
    }
    \strng{namehash}{DGCCSDPM1}
    \strng{fullhash}{DGCCSDPM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{labelyear}{2018}
    \field{labeldatesource}{}
    \field{sortinit}{D}
    \field{sortinithash}{D}
    \field{abstract}{%
    The problem of learning-to-learn (LTL) or meta-learning is gaining
  increasing attention due to recent empirical evidence of its effectiveness in
  applications. The goal addressed in LTL is to select an algorithm that works
  well on tasks sampled from a meta-distribution. In this work, we consider the
  family of algorithms given by a variant of Ridge Regression, in which the
  regularizer is the square distance to an unknown mean vector. We show that,
  in this setting, the LTL problem can be reformulated as a Least Squares (LS)
  problem and we exploit a novel meta-algorithm to efficiently solve it. At
  each iteration the meta-algorithm processes only one dataset. Specifically,
  it firstly estimates the stochastic LS objective function, by splitting this
  dataset into two subsets used to train and test the inner algorithm,
  respectively. Secondly, it performs a stochastic gradient step with the
  estimated value. Under specific assumptions, we present a bound for the
  generalization error of our meta-algorithm, which suggests the right
  splitting parameter to choose. When the hyper-parameters of the problem are
  fixed, this bound is consistent as the number of tasks grows, even if the
  sample size is kept constant. Preliminary experiments confirm our theoretical
  findings, highlighting the advantage of our approach, with respect to
  independent task learning.%
    }
    \field{issn}{10495258}
    \field{number}{NeurIPS}
    \field{pages}{10169\bibrangedash 10179}
    \field{title}{{Learning to learn around a common mean}}
    \field{volume}{2018-Decem}
    \verb{file}
    \verb :home/taylanot/Dropbox/PhD/Papers/subjects/lit_rev_miguel/8220-learni
    \verb ng-to-learn-around-a-common-mean.pdf:pdf
    \endverb
    \field{journaltitle}{Advances in Neural Information Processing Systems}
    \field{year}{2018}
  \endentry
\enddatalist
\endinput
