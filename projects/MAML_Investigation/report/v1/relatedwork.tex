
Since its publications, MAML \cite{Finn2017} opened a wide range of research path that tries to understand gradient-based meta-learning, which aims to find an intermediate model to be used for adaptation at a later stage. There is both empirical and theoretical work dedicated to the understanding of MAML.

The empirical works try to understand and improve the MAML algorithm. For example, the sensitivity of MAML to architectural details and the difficulty in the training of the MAML algorithm is addressed and tackled in \cite{Antoniou2019} under the name of MAML++. This method tries to provide a much more stable algorithm by overcoming the gradient instability, the absence of batch statistics accumulation, the shared bias per layer, constant learning rates utilized in the algorithm. Although, its training difficulties the generalization capabilities are empirically investigated in \cite{Guiroy2019a} and concluded that the generalization to new tasks can be related to the similarity between the trajectories encountered during meta-training and the adaptation procedures. Moreover, in the same work, $L_2$ regularization like regularization for the inner loop is proposed for improved generalization performance. 

Aside from empirical studies, some theoretical work tries to understand the convergence and the generalization of MAML over the past years. However, since the theoretical investigation of the over-parametrized neural network is quite cumbersome, most of the effort goes into understanding this algorithm in much milder settings with strong assumptions. For instance, in \cite{Khodak2019} various gradient-based meta-learning algorithms including MAML and its derivatives are investigated for convex optimization problems and their usefulness is shown compared to single-task learning. In addition, negative learning rates in the inner loop are shown to be optimal during the meta-training stage, theoretically, in \cite{Bernacchia2021} for a mixed linear regression problem. Moreover, in \cite{Collins2020b} the effect of task distribution is investigated for linear regression problems and show that when tasks seen in training are similar to to the ones seen at adaptation step. Finally, in \cite{Fallah2021} the generalization of MAML is investigated from the algorithmic stability and generalization bounds perspective and concluded that the MAML generalizes well even to an unseen task if the training and test task distributions are sufficiently close. 


Another line of work tries to come up with other meta-learning scenarios involving convex settings by construction, which is a quite rare setting in meta-learning paradigm. In \cite{Denevi2018a, Denevi2019} meta-learning models inspired by the biased regularization works \cite{Kuzborskij2017, Kuzborskij2017a}, where bias is tried to be learned from the task environment by minimizing the \textit{Transfer Risk} (Expected Loss), is proposed. Due to the convex nature of the problem, the theoretical foundation is also provided for the proposed models. For learning-to-learn and continual learning settings. On top of this work, \cite{Bai2020} investigate the need for \textit{train-test} split for the same models and concludes that the \textit{train-train} model achieves strictly better generalization performance for structured tasks in the setting of learning around a common mean problem presented in \cite{Denevi2018a}. However, the comparision of this method to other meta-learning methods (\eg MAML) are left out.


\paragraph{Our Contribution:} The \textit{Expected Loss} investigation for most of the meta-learning methods are left out for various reasons. We try to investigate this for two different meta learning approaches. On one hand, the loss MAML \cite{Finn2017} is trying to optimize is the loss that the model would make given a batch of tasks obtained from the environment of certain task distribution. The model parameters update is done by looking at the possible loss for each task if the model parameters are changed for a certain task. On the other hand, the methods proposed by \cite{Denevi2018a} are trying to optimize for the so-called \textit{Transfer Risk} over for the task distribution. The main contribution of this paper is to investigate in linear and nonlinear settings the average performance of the MAML algorithm by looking at its expected loss, which will then be compared to individual learning task performance where there is no information coming from the task environment. The reason that the expected loss of MAML is not investigated can be speculated to be the computational burden that it bestows upon the problem. Here, for the linear problem case, this problem is tried to be elevated utilizing NUMBA \cite{Lam2015}, which can create compiled code for Python. However, due to the inflexibility of the NUMBA, pure PyTorch \cite{Paszke2019} implementation, which is slower, is used for the nonlinear problem with a lesser degree of fidelity. 

