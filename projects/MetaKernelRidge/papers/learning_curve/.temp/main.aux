\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ma2017}
\citation{kiefer1952}
\citation{mohr}
\citation{looga}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Learning curve extrapolation visualization for both training and test performance with an error measure concerning the training set size $N$.\relax }}{1}{figure.caption.1}\protected@file@percent }
\citation{scholkopf2002a}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:rw}{{2}{2}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Setting}{2}{section.3}\protected@file@percent }
\newlabel{sec:prob}{{3}{2}{Problem Setting}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{2}{section.4}\protected@file@percent }
\newlabel{sec:meth}{{4}{2}{Methods}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Semi-Parametric Kernel Ridge}{2}{subsection.4.1}\protected@file@percent }
\newlabel{eq:data}{{3}{2}{Semi-Parametric Kernel Ridge}{equation.4.3}{}}
\citation{scholkopf2002a}
\newlabel{eq:min}{{4}{3}{Semi-Parametric Kernel Ridge}{equation.4.4}{}}
\newlabel{eq:min_semi}{{5}{3}{Semi-Parametric Kernel Ridge}{equation.4.5}{}}
\newlabel{eq:opt}{{7}{3}{Semi-Parametric Kernel Ridge}{equation.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Discussion}{3}{section.5}\protected@file@percent }
\newlabel{sec:resdis}{{5}{3}{Results and Discussion}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Learning Monotone Learning Curves}{3}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Learning curve prediction for changing hyper-parameters of the same model and same dataset}{3}{subsubsection.5.1.1}\protected@file@percent }
\newlabel{sec:same}{{5.1.1}{3}{Learning curve prediction for changing hyper-parameters of the same model and same dataset}{subsubsection.5.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Learning curve prediction for tuned hyper-parameter of the same model and different datasets}{3}{subsubsection.5.1.2}\protected@file@percent }
\newlabel{sec:diff-dataset}{{5.1.2}{3}{Learning curve prediction for tuned hyper-parameter of the same model and different datasets}{subsubsection.5.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Learning Non-monotone Learning Curves}{3}{subsection.5.2}\protected@file@percent }
\bibstyle{unsrt}
\bibdata{/home/taylanot/Dropbox/archive_bib/LearningCurve.bib,/home/taylanot/Dropbox/archive_bib/SPKR.bib}
\bibcite{ma2017}{1}
\bibcite{kiefer1952}{2}
\bibcite{mohr}{3}
\bibcite{looga}{4}
\bibcite{scholkopf2002a}{5}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Performance against baselines}{4}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{4}{section.6}\protected@file@percent }
\newlabel{sec:conc}{{6}{4}{Conclusion}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{5}{section.7}\protected@file@percent }
\newlabel{sec:conc}{{7}{5}{Appendix}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Learning Curves for Semiparameteric Kernel Ridge}{5}{subsection.7.1}\protected@file@percent }
\newlabel{app:1}{{7.1}{5}{Learning Curves for Semiparameteric Kernel Ridge}{subsection.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Hypothesis Testing for the Semiparametric Kernel Ridge}{5}{subsection.7.2}\protected@file@percent }
\newlabel{app:2}{{7.2}{5}{Hypothesis Testing for the Semiparametric Kernel Ridge}{subsection.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}FPCA for information extraction from the available learning curves}{5}{subsection.7.3}\protected@file@percent }
\newlabel{app:3}{{7.3}{5}{FPCA for information extraction from the available learning curves}{subsection.7.3}{}}
