% Negative sides of its
Upon our investigation, we observed that single-task learners are able to compete with MAML when a limited number of gradient steps are allowed. We show that even in the case of general regularization, and when there is enough data, a single-task learner can outperform on expectation of a meta learner. Especially when the tasks observed start to deviate from each other. It indicates that the regularization-based meta-learners similar to the ones presented in \cite{denevi2018}, can be competitive and robust enough for much wider task variance. However, it also should be suitable for nonlinear problem settings.  Moreover, regularization-based methods similar to the ones presented in \cite{guiroy2019} for MAML can prove useful to extend the generalization performance of MAML to wider task variances. 

This study only utilizes synthetic data, since the computational burden of expected error analysis is high. Thus, more in-depth expected performance should be done for the Omniglot dataset and other widely used supervised few-shot learning benchmark datasets with improvements introduced on top of MAML. We believe that understanding all the contributing factors to generalization performance is key to correct use cases of meta-learning methods.


